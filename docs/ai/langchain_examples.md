# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LangChain –∏ LangGraph

## –û–±–∑–æ—Ä

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LangChain –∏ LangGraph –≤ Telegram-–±–æ—Ç–µ –¥–ª—è –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.

## 1. –ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LangChain

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –∏ Embeddings
```python
# app/ai/langchain/config.py
import os
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.callbacks import get_openai_callback

class LangChainConfig:
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.7,
            openai_api_key=self.openai_api_key,
            max_tokens=1000
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Embeddings
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002",
            openai_api_key=self.openai_api_key
        )
    
    def get_llm(self):
        return self.llm
    
    def get_embeddings(self):
        return self.embeddings
    
    def track_usage(self, callback_func):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤"""
        with get_openai_callback() as cb:
            result = callback_func()
            return result, {
                "total_tokens": cb.total_tokens,
                "prompt_tokens": cb.prompt_tokens,
                "completion_tokens": cb.completion_tokens,
                "total_cost": cb.total_cost
            }
```

## 2. LangGraph Workflow –¥–ª—è RAG

### –ü–æ–ª–Ω—ã–π RAG Workflow
```python
# app/ai/langgraph/rag_workflow.py
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import StrOutputParser

class RAGState(TypedDict):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ RAG workflow"""
    original_query: str
    user_id: int
    language: str
    enhanced_query: str
    retrieved_documents: List[Document]
    context: str
    final_response: str
    metadata: Dict[str, Any]

class RAGWorkflow:
    def __init__(self, llm, embeddings, vector_store):
        self.llm = llm
        self.embeddings = embeddings
        self.vector_store = vector_store
        
        # –°–æ–∑–¥–∞–Ω–∏–µ workflow
        workflow = StateGraph(RAGState)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤
        workflow.add_node("detect_language", self.detect_language)
        workflow.add_node("enhance_query", self.enhance_query)
        workflow.add_node("retrieve_documents", self.retrieve_documents)
        workflow.add_node("generate_response", self.generate_response)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–æ–≤
        workflow.set_entry_point("detect_language")
        workflow.add_edge("detect_language", "enhance_query")
        workflow.add_edge("enhance_query", "retrieve_documents")
        workflow.add_edge("retrieve_documents", "generate_response")
        workflow.add_edge("generate_response", END)
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
        self.app = workflow.compile()
    
    async def detect_language(self, state: RAGState) -> RAGState:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"""
        from langdetect import detect
        
        try:
            detected_lang = detect(state["original_query"])
            state["language"] = detected_lang
        except:
            state["language"] = "ru"
        
        state["metadata"]["detected_language"] = state["language"]
        return state
    
    async def enhance_query(self, state: RAGState) -> RAGState:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        enhancement_prompt = ChatPromptTemplate.from_template("""
        –£–ª—É—á—à–∏ —Å–ª–µ–¥—É—é—â–∏–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.
        –î–æ–±–∞–≤—å —Å–∏–Ω–æ–Ω–∏–º—ã –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Å—Ö–æ–¥–Ω—ã–π —Å–º—ã—Å–ª.
        
        –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {query}
        –Ø–∑—ã–∫: {language}
        
        –£–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å:
        """)
        
        chain = enhancement_prompt | self.llm | StrOutputParser()
        
        enhanced = await chain.ainvoke({
            "query": state["original_query"],
            "language": state["language"]
        })
        
        state["enhanced_query"] = enhanced.strip()
        return state
    
    async def retrieve_documents(self, state: RAGState) -> RAGState:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        retriever = self.vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 10,
                "score_threshold": 0.7
            }
        )
        
        docs = await retriever.aget_relevant_documents(state["enhanced_query"])
        state["retrieved_documents"] = docs
        state["metadata"]["retrieved_count"] = len(docs)
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_parts = []
        for i, doc in enumerate(docs):
            context_parts.append(f"–î–æ–∫—É–º–µ–Ω—Ç {i+1}: {doc.page_content}")
        
        state["context"] = "\n\n".join(context_parts)
        return state
    
    async def generate_response(self, state: RAGState) -> RAGState:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        response_prompt = ChatPromptTemplate.from_template("""
        –¢—ã - –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {context}
        
        –í–æ–ø—Ä–æ—Å: {query}
        –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞: {language}
        
        –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
        - –û—Ç–≤–µ—á–∞–π –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        - –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º
        - –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
        - –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        
        –û—Ç–≤–µ—Ç:
        """)
        
        chain = response_prompt | self.llm | StrOutputParser()
        
        response = await chain.ainvoke({
            "context": state["context"],
            "query": state["original_query"],
            "language": state["language"]
        })
        
        state["final_response"] = response.strip()
        return state
    
    async def process_query(self, query: str, user_id: int) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        initial_state = RAGState(
            original_query=query,
            user_id=user_id,
            language="",
            enhanced_query="",
            retrieved_documents=[],
            context="",
            final_response="",
            metadata={}
        )
        
        final_state = await self.app.ainvoke(initial_state)
        
        return {
            "response": final_state["final_response"],
            "language": final_state["language"],
            "retrieved_count": final_state["metadata"]["retrieved_count"],
            "enhanced_query": final_state["enhanced_query"]
        }
```

## 3. LangChain Agents –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π

### –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏
```python
# app/ai/langchain/agents.py
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import BaseTool
from langchain.prompts import ChatPromptTemplate
from typing import Type, Optional
from pydantic import BaseModel, Field

class UserSearchInput(BaseModel):
    name: str = Field(description="–ò–º—è –∏–ª–∏ —Ñ–∞–º–∏–ª–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞")
    department: Optional[str] = Field(description="–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")

class UserSearchTool(BaseTool):
    name = "search_employee"
    description = "–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –∏–º–µ–Ω–∏ –∏–ª–∏ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—É"
    args_schema: Type[BaseModel] = UserSearchInput
    
    def __init__(self, user_service):
        super().__init__()
        self.user_service = user_service
    
    async def _arun(self, name: str, department: Optional[str] = None) -> str:
        users = await self.user_service.search_users(
            query=name,
            department=department
        )
        
        if not users:
            return f"–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å –∏–º–µ–Ω–µ–º '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        result = f"–ù–∞–π–¥–µ–Ω–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {len(users)}\n"
        for user in users[:5]:
            result += f"‚Ä¢ {user.first_name} {user.last_name} - {user.department} ({user.position})\n"
        
        return result

class PolicySearchInput(BaseModel):
    topic: str = Field(description="–¢–µ–º–∞ –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –ø–æ–ª–∏—Ç–∏–∫–∞—Ö –∫–æ–º–ø–∞–Ω–∏–∏")

class PolicySearchTool(BaseTool):
    name = "search_policy"
    description = "–ü–æ–∏—Å–∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª–∏—Ç–∏–∫ –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä –ø–æ —Ç–µ–º–µ"
    args_schema: Type[BaseModel] = PolicySearchInput
    
    def __init__(self, document_service):
        super().__init__()
        self.document_service = document_service
    
    async def _arun(self, topic: str) -> str:
        documents = await self.document_service.search_documents(
            query=topic,
            category="policy"
        )
        
        if not documents:
            return f"–ü–æ–ª–∏—Ç–∏–∫–∏ –ø–æ —Ç–µ–º–µ '{topic}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        result = f"–ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–∏—Ç–∏–∫: {len(documents)}\n"
        for doc in documents[:3]:
            result += f"‚Ä¢ {doc.title}\n"
        
        return result

class CorporateAgent:
    def __init__(self, llm, user_service, document_service):
        self.llm = llm
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self.tools = [
            UserSearchTool(user_service),
            PolicySearchTool(document_service)
        ]
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """
            –¢—ã - –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –Ω–æ–≤—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
            –£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–ª–µ–¥—É—é—â–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º:
            - search_employee: –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–≥–∞—Ö
            - search_policy: –ø–æ–∏—Å–∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª–∏—Ç–∏–∫
            
            –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:
            - –°–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –∫–æ–ª–ª–µ–≥–∞—Ö –∏–ª–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞—Ö
            - –ò–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏
            - –ù—É–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞—Ö
            
            –í—Å–µ–≥–¥–∞ –±—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º.
            """),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
        self.agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=3
        )
    
    async def process_query(self, query: str) -> str:
        result = await self.agent_executor.ainvoke({"input": query})
        return result["output"]
```

## 4. Conversational RAG —Å –ø–∞–º—è—Ç—å—é

### –î–∏–∞–ª–æ–≥–æ–≤—ã–π RAG —Å –∏—Å—Ç–æ—Ä–∏–µ–π
```python
# app/ai/langchain/conversational_rag.py
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage

class ConversationalRAG:
    def __init__(self, llm, vector_store, memory_size: int = 10):
        self.llm = llm
        self.vector_store = vector_store
        
        # –ü–∞–º—è—Ç—å –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
        self.memory = ConversationBufferWindowMemory(
            k=memory_size,
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ conversational chain
        self.chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vector_store.as_retriever(),
            memory=self.memory,
            return_source_documents=True,
            verbose=True,
            combine_docs_chain_kwargs={
                "prompt": self._get_qa_prompt()
            }
        )
    
    def _get_qa_prompt(self):
        from langchain.prompts import PromptTemplate
        
        return PromptTemplate(
            template="""
            –ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
            –ï—Å–ª–∏ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å.
            
            –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}
            
            –í–æ–ø—Ä–æ—Å: {question}
            
            –ü–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç:
            """,
            input_variables=["context", "question"]
        )
    
    async def chat(self, message: str, user_id: int) -> Dict[str, Any]:
        """–î–∏–∞–ª–æ–≥–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
        result = await self.chain.acall({
            "question": message,
            "chat_history": self.memory.chat_memory.messages
        })
        
        return {
            "answer": result["answer"],
            "source_documents": [
                {
                    "content": doc.page_content[:200] + "...",
                    "source": doc.metadata.get("title", "Unknown")
                }
                for doc in result["source_documents"]
            ],
            "chat_history_length": len(self.memory.chat_memory.messages)
        }
    
    def get_chat_history(self) -> List[Dict[str, str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        history = []
        for message in self.memory.chat_memory.messages:
            history.append({
                "type": "human" if isinstance(message, HumanMessage) else "ai",
                "content": message.content
            })
        return history
    
    def clear_history(self):
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        self.memory.clear()
```

## 5. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Telegram Bot

### Bot handlers —Å LangChain
```python
# app/bot/handlers/langchain_handlers.py
from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup

class ConversationStates(StatesGroup):
    chatting = State()
    agent_mode = State()

class LangChainBotHandlers:
    def __init__(
        self,
        rag_workflow,
        conversational_rag,
        corporate_agent
    ):
        self.rag_workflow = rag_workflow
        self.conversational_rag = conversational_rag
        self.corporate_agent = corporate_agent
        self.router = Router()
        
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è handlers
        self._register_handlers()
    
    def _register_handlers(self):
        self.router.message(Command("rag"))(self.rag_search)
        self.router.message(Command("chat"))(self.start_conversation)
        self.router.message(Command("agent"))(self.agent_mode)
        self.router.message(ConversationStates.chatting)(self.continue_conversation)
        self.router.message(ConversationStates.agent_mode)(self.agent_query)
    
    async def rag_search(self, message: Message, user: User):
        """–û–¥–∏–Ω–æ—á–Ω—ã–π RAG –ø–æ–∏—Å–∫"""
        query = message.text.replace("/rag", "").strip()
        
        if not query:
            await message.answer(
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /rag\n"
                "–ù–∞–ø—Ä–∏–º–µ—Ä: /rag –∫–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ VPN"
            )
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–µ—á–∞—Ç–∏
        await message.bot.send_chat_action(message.chat.id, "typing")
        
        try:
            result = await self.rag_workflow.process_query(query, user.id)
            
            response_text = result["response"]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if result["retrieved_count"] > 0:
                response_text += f"\n\nüìö –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {result['retrieved_count']}"
                response_text += f"\nüîç –£–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {result['enhanced_query']}"
            
            await message.answer(response_text)
            
        except Exception as e:
            await message.answer(
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            )
    
    async def start_conversation(self, message: Message, state: FSMContext, user: User):
        """–ù–∞—á–∞–ª–æ –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        await state.set_state(ConversationStates.chatting)
        
        query = message.text.replace("/chat", "").strip()
        
        if query:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø—Ä–æ—Å, —Å—Ä–∞–∑—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            await self.continue_conversation(message, state, user)
        else:
            await message.answer(
                "üó£ –î–∏–∞–ª–æ–≥–æ–≤—ã–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!\n"
                "–¢–µ–ø–µ—Ä—å —è –±—É–¥—É –ø–æ–º–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞—à–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.\n"
                "–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /stop –¥–ª—è –≤—ã—Ö–æ–¥–∞."
            )
    
    async def continue_conversation(self, message: Message, state: FSMContext, user: User):
        """–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞"""
        if message.text == "/stop":
            await state.clear()
            self.conversational_rag.clear_history()
            await message.answer("–î–∏–∞–ª–æ–≥–æ–≤—ã–π —Ä–µ–∂–∏–º –∑–∞–≤–µ—Ä—à–µ–Ω.")
            return
        
        await message.bot.send_chat_action(message.chat.id, "typing")
        
        try:
            result = await self.conversational_rag.chat(message.text, user.id)
            
            response_text = result["answer"]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            if result["source_documents"]:
                response_text += "\n\nüìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏:"
                for doc in result["source_documents"][:2]:
                    response_text += f"\n‚Ä¢ {doc['source']}"
            
            await message.answer(response_text)
            
        except Exception as e:
            await message.answer(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –¥–∏–∞–ª–æ–≥–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /stop –¥–ª—è –≤—ã—Ö–æ–¥–∞."
            )
    
    async def agent_mode(self, message: Message, state: FSMContext, user: User):
        """–†–µ–∂–∏–º –∞–≥–µ–Ω—Ç–∞ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏"""
        await state.set_state(ConversationStates.agent_mode)
        
        query = message.text.replace("/agent", "").strip()
        
        if query:
            await self.agent_query(message, state, user)
        else:
            await message.answer(
                "ü§ñ –†–µ–∂–∏–º –∞–≥–µ–Ω—Ç–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!\n"
                "–Ø –º–æ–≥—É –ø–æ–º–æ—á—å –Ω–∞–π—Ç–∏ –∫–æ–ª–ª–µ–≥ –∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–ª–∏—Ç–∏–∫–∏.\n"
                "–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /stop –¥–ª—è –≤—ã—Ö–æ–¥–∞."
            )
    
    async def agent_query(self, message: Message, state: FSMContext, user: User):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞"""
        if message.text == "/stop":
            await state.clear()
            await message.answer("–†–µ–∂–∏–º –∞–≥–µ–Ω—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω.")
            return
        
        await message.bot.send_chat_action(message.chat.id, "typing")
        
        try:
            response = await self.corporate_agent.process_query(message.text)
            await message.answer(response)
            
        except Exception as e:
            await message.answer(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –∞–≥–µ–Ω—Ç–æ–º. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            )
```

## 6. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ—Ç–ª–∞–¥–∫–∞ LangChain

### Callbacks –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
```python
# app/ai/langchain/monitoring.py
from langchain.callbacks.base import BaseCallbackHandler
from typing import Dict, Any, List
import time
import logging

class TelegramBotCallbackHandler(BaseCallbackHandler):
    """Callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ LangChain –æ–ø–µ—Ä–∞—Ü–∏–π"""
    
    def __init__(self):
        self.start_time = None
        self.tokens_used = 0
        self.cost = 0.0
        self.logger = logging.getLogger(__name__)
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """–ù–∞—á–∞–ª–æ LLM –∑–∞–ø—Ä–æ—Å–∞"""
        self.start_time = time.time()
        self.logger.info(f"LLM –∑–∞–ø—Ä–æ—Å –Ω–∞—á–∞—Ç. –ü—Ä–æ–º–ø—Ç–æ–≤: {len(prompts)}")
    
    def on_llm_end(self, response, **kwargs) -> None:
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ LLM –∑–∞–ø—Ä–æ—Å–∞"""
        duration = time.time() - self.start_time if self.start_time else 0
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–∫–µ–Ω–∞—Ö
        if hasattr(response, 'llm_output') and response.llm_output:
            token_usage = response.llm_output.get('token_usage', {})
            self.tokens_used = token_usage.get('total_tokens', 0)
        
        self.logger.info(
            f"LLM –∑–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–µ–Ω. –í—Ä–µ–º—è: {duration:.2f}—Å, –¢–æ–∫–µ–Ω—ã: {self.tokens_used}"
        )
    
    def on_llm_error(self, error: Exception, **kwargs) -> None:
        """–û—à–∏–±–∫–∞ LLM"""
        self.logger.error(f"–û—à–∏–±–∫–∞ LLM: {error}")
    
    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs) -> None:
        """–ù–∞—á–∞–ª–æ —Ü–µ–ø–æ—á–∫–∏"""
        chain_name = serialized.get('name', 'Unknown')
        self.logger.info(f"–¶–µ–ø–æ—á–∫–∞ '{chain_name}' –Ω–∞—á–∞—Ç–∞")
    
    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏"""
        self.logger.info("–¶–µ–ø–æ—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    
    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """–ù–∞—á–∞–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        tool_name = serialized.get('name', 'Unknown')
        self.logger.info(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç '{tool_name}' –∑–∞–ø—É—â–µ–Ω —Å –≤—Ö–æ–¥–æ–º: {input_str[:100]}...")
    
    def on_tool_end(self, output: str, **kwargs) -> None:
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        self.logger.info(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –í—ã—Ö–æ–¥: {output[:100]}...")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ callback
def create_monitored_llm():
    from langchain.chat_models import ChatOpenAI
    
    callback_handler = TelegramBotCallbackHandler()
    
    llm = ChatOpenAI(
        model="gpt-4",
        callbacks=[callback_handler],
        verbose=True
    )
    
    return llm, callback_handler
```

–≠—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, –∫–∞–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å LangChain –∏ LangGraph –≤ Telegram-–±–æ—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ—â–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–ª–æ–∂–Ω—ã—Ö AI workflows, –∞–≥–µ–Ω—Ç–æ–≤ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –∏ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤.